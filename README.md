## Masterskaya_2_YDS — классификация отклика клиентов

Проект решает задачу бинарной классификации отклика клиента на коммуникации/маркетинговые активности на основе истории сообщений и покупок. Исходники представлены в блокноте `ms-2-yds.ipynb`.

### Данные
- `apparel-messages.csv`: события коммуникаций (`send`, `open`, `click`, `unsubscribe`, и др.), каналы (`email`, `mobile_push`), временные метки.
- `apparel-purchases.csv`: покупки с количеством, ценой и иерархией категорий `category_ids`.
- `apparel-target_binary.csv`: таргет на уровне `client_id` (0/1).

После очистки явных дубликатов формируются фичи на уровне клиента:
- RFM и агрегаты по покупкам: суммы/средние/медианы/стандарты, число заказов, давность (`recency_days`), «возраст клиента» и др.
- Парсинг категорий: глубина, первый/последний уровень, топ-N (50) индикаторов по самым частым категориям, уникальные множества категорий.
- Оконная активность за 30/60/90 дней по суммам/количеству/числу заказов.
- Агрегаты по сообщениям: количество событий по типам, число уникальных `message_id`, давность коммуникаций.

Итоговый датафрейм признаков имеет ~97 столбцов на 49 849 клиентов.

### Снижение размерности
Признаки стандартизируются и по ним обучается PCA. Выбирается число компонент, обеспечивающих ~90% объяснённой дисперсии (≈45 компонент). Итоговый датасет для модели: 45 компонент + `client_id` + `target`.

### Модели
1. RandomForestClassifier (поиск гиперпараметров через RandomizedSearchCV, метрика AUC, StratifiedKFold).
2. CatBoostClassifier (RandomizedSearchCV, AUC).

Оценка на отложенной выборке (20%, стратификация):
- Класс сильно несбалансирован: ~48 888 нулей и 961 единица (примерно 1:51).
- Лучший AUC около 0.72–0.73. Порог подбирается по максимуму precision.

### Быстрый старт (локально)
1) Установите зависимости:
```bash
pip install -r requirements.txt
```
2) Откройте `ms-2-yds.ipynb` и выполните блокнот целиком. Обновите пути к данным, если они отличаются от Kaggle-путей.

### Почему плохо определяется класс 1
В блокноте оптимизация порога производится по максимизации precision. При сильной дисбалансировке это смещает решение в пользу предсказания класса 0 реже, но «чище», что часто повышает precision класса 1 ценой снижения recall класса 0 и одновременного роста количества предсказаний класса 1. Такой сдвиг порога может ухудшить качество распознавания класса 1 в конфузионной матрице в терминах метрик, завязанных на его полноту/точность, или создать ощущение «плохого определения» класса 0, если бизнес-задаче важен баланс обеих ошибок.

Дополнительные причины и факторы:
- Сильный дизбаланс таргета (~1:51). Модель стремится «игнорировать» редкий класс.
- Оптимизация по AUC и затем по precision не гарантирует оптимальные метрики для класса 0 (например, specificity/NPV).
- PCA смешивает информативные и шумовые проекции; без таргетного отбора признаков возможно размывание сигналов класса 0/1.
- Потенциальные утечки метрик сообщений по времени: нужно строго блюсти временной разрез между признаками и целевым окном.
- Ограниченная мощность моделей/подбор гиперпараметров (10 итераций) при большом признаковом пространстве.

### Рекомендации по улучшению
- Использовать стратифицированные сплиты по времени (time-based split) и фичи только из прошлого относительно таргета.
- Баланс классов: class_weight, undersampling majority или oversampling minority (SMOTE), focal loss (для градиентных бустингов).
- Подбор порога под нужную бизнес-метрику: оптимизация по Youden J, по F1-макро, по balanced accuracy, по минимизации стоимости ошибок, по specificity/NPV, если важен класс 0.
- Увеличить поиск гиперпараметров (итерации, сетка), попробовать LightGBM/XGBoost с scale_pos_weight.
- Вместо глобального PCA попробовать таргетные методы: отбор по важности (Permutation/SHAP), регуляризация, отбрасывание сильно коррелирующих признаков.
- Кросс-валидация с повторениями и калибровка вероятностей (Platt/Isotonic) для лучшей калибровки порога.

### Структура репозитория
- `ms-2-yds.ipynb` — основной анализ и обучение моделей.
- `README.md` — это описание.
- `requirements.txt` — зависимости для воспроизведения.

### Лицензия
Свободное использование в учебных целях.


